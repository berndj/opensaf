#
#      -*- OpenSAF  -*-
#
# (C) Copyright 2008 The OpenSAF Foundation
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
# or FITNESS FOR A PARTICULAR PURPOSE. This file and program are licensed
# under the GNU Lesser General Public License Version 2.1, February 1999.
# The complete license can be accessed from the following location:
# http://opensource.org/licenses/lgpl-license.php
# See the Copying file included with the OpenSAF distribution for full
# licensing terms.
#
# Author(s): Ericsson AB
#

GENERAL
=======

This directory (logsv) contains an implementation of the SAF LOG service
version A.02.01.

The LOG service is implemented as a server process executing on the controllers
using a 2N redundancy model. Message based checkpointing is
used to synchronize the two server instances.

The Log file property "High Availability flag" is not supported by LOG itself
but by using a replicated file system. The LOG implementation is unaware of 
such a file system and must be configured to use it, see below.


Important!
----------
Contributors/Maintainers see section
IMPORTANT INFORMATION FOR CONTRIBUTORS/MAINTAINERS.


DEPENDENCIES
============

logsv depends of the following other OpenSAF services:
- MBCSV
- MDS
- BASE
- logtrace


DIRECTORY STRUCTURE
===================

services/logsv/inc	Common header files used by both lga and lgs
services/logsv/lga	LOG library implementation
services/logsv/lgs	LOG server
services/logsv/utils	saflogger command
lib/lib_SaLog		LOG library staging
tests/logsv/src		Test suite


DATA STRUCTURES
===============

lgs uses the following data structures:

- Control block. Statically allocated, one instance. Access through a global
pointer variable.

- Stream descriptors. Dynamically created, many instances. Accessed using
stream name or ID. Stored in Map and array.

- Client descriptors. Dynamically created, many instances. Accessed using a
client ID. Stored in Map. Contains the MDS address of the client.
Also contains a list of Client-Stream association objects, see below.

- Client-Stream association object. Dynamically created, many instances. One
instance per open stream. Contains a stream ID. Access through client
descriptor.

lga uses the following data structures:

- Control block. Statically allocated, one instance per library. Access
through a global variable. The control block contains the head of a linked
list with client descriptors.

- Client descriptor. Dynamically allocated. One instance per call to
saLogInitialize(). Contains callback pointers, handles and the head of a
linked list with streams descriptors for this client.

- Stream descriptor. Dynamically allocated. One instance per call to
saLogStreamOpen_2() or saLogStreamOpenAsync_2(). Contains internals IDs
and handles.


OVERLOAD PROTECTION
===================

LOG uses a single mailbox used to communicate from the MDS thread to the
main thread. An IPC mailbox has four priority levels. By default a level
is unbounded in size, as many messages as the main memory allows can be
queued. The mailbox provides a mechanism to put a limit on how many
messages that can be stored at the same time in it. LOG overload uses
that feature.

The highest level is used for control messages except for FINALIZE & CLOSE
messages. The reason is that we want to keep those at the same priority as
WRITE messages so that no writes will get discarded when a stream is closed
or a client finalize the API. The three other mailbox priority levels are
used for WRITE messages per stream type. Alarm use the next level, System
and Notification share the next level and all application streams share the
lowest priority level. The alarm level can never be bounded in size.

The levels used for system and application streams has an optional
configurable LOW and HIGH limit of queued messages. When the high limit
is hit, the level enters the FULL state. This state will not be left 
until the number of messages goes below the LOW limit. Messages received
in the meantime will be nacked with a TRYAGAIN, but only if the client has
requested so in the log record header. Otherwise it will be silently
discarded (but counted as such). CLOSE & FINALIZE messages will never be
rejected even though the level is full. If that happens, the message is
queued at the (unlimited) control message level.

Log records will be handled by the LOG server in the same priority.
All Alarm log records will be written to disk before any System/notification
log records. All System/notification log records will be written to disk
before any application log records are written to disk. This reduces the
risk to loose any important system events at sudden failure such as power
outage.

The low/high limits for system and app streams are configurable. See the
next section. Different app streams share the same limits.


CONFIGURATION
=============

Some implementation defined configurations can be done for the LOG service.

Streams
-------
The LOG specification describes the configuration object class 
SaLogStreamConfig which requires the three streams alarm, notification and 
system to exist (in IMM). The two LOG classes and objects for the three
default streams are included in the OpenSAF IMM configuration.

Service configuration
---------------------
There is also a configuration object class OpenSafLogConfig used to configure
the LOG Service itself and a runtime object class OpenSafLogCurrentConfig making
it possible to read the configuration.
These classes are not described in the LOG AIS specification.

There are three sources where the log server may get configuration data; an
OpenSafLogConfig IMM object, environment variables or hard coded default values.
The main source for configuration data is the configuration object but if this
object does not exist attributes are empty or contains incorrect values data
will be fetched from environment variables if exist. If no valid configuration
data is available a hard coded default value will be used.
The reason for not only using a configuration object is that the log service
must always be able to start.
Environment variables are supported in order to be backwards compatible. Before
a configuration object was introduced environment variables were used. In the
future when new configuration parameters are added no corresponding environment
variables will be supported.

1. IMM configuration object
---------------------------
The name of the class is:
"OpenSafLogConfig"
The name of the configuration object is:
"logConfig=1,safApp=safLogService"

The class defines the following parameters and default values for the object
(logsv_classes.xml):

NAME                        DEFAULT VALUE         COMMENT
logRootDirectory            $pkglogdir/saflog     Must be available in the file
                                                  system
logMaxLogrecsize            1024                  Max log record size including
                                                  header information
logStreamFileFormat         <empty>               c.
logStreamSystemHighLimit    0                     a.
logStreamSystemLowLimit     0                     a.
logAppHighLimit             0                     a.
logAppLowLimit              0                     a.
logMaxApplicationStreams    64                    Max number of application
                                                  streams with runtime object
                                                  that can be created
logFileIoTimeout            500                   File I/O timeout (see file.c)
logFileSysConfig            1                     Shared file system b.
logDataGroupname            <Empty>               Groupname used to share log data.

a. Message queue thresholds used when queuing log record write requests of
   different types
b. Log service can be configured to write log records locally on both server
   nodes. This attribute cannot be changed in runtime
c. The default format for application log records created using the log API.
   If this attribute has no value <empty> a hard coded format as defined in the
   log service AIS will be used as default format.

A value for parameter saLogRootDirectory is instead defined when the imm.xml file is created.
In the logsv_objects.xml file the parameter value is set to "xxLOGDIRxx/saflog"
and when the imm.xml file is created "xxLOGDIRxx" is replaced by the content of
$pkglogdir.

The configuration file is still used to "enable trace" and
"enable info level logging". Also the environment variable
LGSV_ENV_HEALTHCHECK_KEY is used.

The following attributes can be changed in runtime.

 - logRootDirectory
   Can be changed to an existing path.

 - logStreamFileFormat
 - logMaxLogrecsize
 - logFileIoTimeout

 - logStreamSystemHighLimit
   logStreamSystemLowLimit
   logAppHighLimit
   logAppLowLimit
   Could not be changed in older versions.

 - logDataGroupname
   Can be changed to an existing group which is currently a supplementary group
   of the user as which LOG service is running.
   This new group then will be used to own all log files. Also the ownership of
   all current log files will be changed to this group for consistent purpose.
   Users who are member of this group then can read the log files.
   After the deletion of the value of this attribute, the ownership of all current
   log files won't be changed and behavior will be kept as previous, i.e: new opened
   log file will be owned by the primary group as which LOG service is running. 

Other attributes cannot be changed in runtime.

logFileIoTimeout

File IO is used in the log service e.g. log records are written to file. File IO
operations may "hang" if for example the file system is not working correctly.
This attribute contains the maximum time the log service is allowed to wait for
e.g. writing a log record to complete. If writing a log record times out
SA_AIS_ERR_TRY_AGAIN is returned in the corresponding callback.

logFileSysConfig

The log service can be configured to use a shared filesystem (default) or to
write logs to two file systems e.g. local file system on SC nodes. In this
configuration both active and standby handle log files.
Possible configurations are:
1 Shared file system
2 Split file system

2. Configuration using a configuration file with environment variables:
----------------------------------------------------------------------
This is the "old" way of handling configuration and is kept for backwards
compatibility and is used if no IMM configuration object is found .
The config file is typically:

/etc/opensaf/logd.conf

The LOG server start script sources the configuration file before it starts
the LOG server. So any change in this will requires a restart of the LOG
server which implies OpenSAF on that node.

The following environment variable is required:

LOGSV_ROOT_DIRECTORY:

This variable is needed to configure the "implementation defined root
directory" as mentioned in the spec. All log files will be stored directly 
in this directory or in a subdirectory. If HA characteristics are needed for
LOG streams, configure this directory to point to replicated (shared & 
persistent) partition.

The following environment variables are optional:

LOGSV_MAX_LOGRECSIZE:

The maximum size of a log record. The size must be at least 256 byte.

LOG_STREAM_SYSTEM_HIGH_LIMIT

The high limit for the system/notification streams. Default unlimited. A
reasonable value would be 300 (messages).

LOG_STREAM_SYSTEM_LOW_LIMIT:

The low limit for the system/notification streams. Only valid and used if
a high limit has been defined. Defaults to some percent of the high limit
(if not specified).

LOG_STREAM_APP_HIGH_LIMIT:

The high limit for all application streams. Default unlimited. A
reasonable value would be 300 (messages).

LOG_STREAM_APP_LOW_LIMIT:

The low limit for the all application streams. Only valid and used if
a high limit has been defined. Defaults to some percent of the high limit
(if not specified).

LOG_MAX_APPLICATION_STREAMS:

The maximum number of application log streams that can be created.

LOGSV_DATA_GROUPNAME:

The group used to share log data to users.
This group must be added as a supplementary group of user as which log service is running.
Any user wants to read log data must become a member of this group.

Don't forget the "export" keyword before the variable!

IMM configuration runtime object
--------------------------------
The name of the class is:
"OpenSafLogConfigRuntime"
The name of the configuration object is:
"logConfig=currentConfig,safApp=safLogService"

Since the log service can use three sources for setting the configuration
parameters there is a possibility that there is a mismatch between the
configuration object and the actual configuration. All attributes in this object
is pure runtime attributes and shows the actual content of each configuration
parameter.
Normally the log service shall be configured using an IMM class matching the
sw version (all attributes exist) and all attributes have a valid value. If this
is the case the configuration object and the actual configuration will match.

Some examples of when there will be a mismatch:
A.
The configuration classes are updated but new parameters has not been given a
value (attributes exist but has empty values)

B.
The configuration object exist and has all attributes but one or more attribute
has an invalid value. This could be the case if a configuration object is
predefined with incorrect values. In this case the log service will use default
values instead of the invalid values.

NOTE: When upgrading to a sw version that has new configuration parameters both
      configuration object classes has to be upgraded to contain the new
      attributes. If the new parameters are not added to the runtime class it
      will not be possible to see the complete configuration. The OpenSAF
      logsv_classes.xml file shall always be updated.


COMMAND LINE INTERFACE
======================

The 'saflogger' command can be used to enter log records to any stream. Please
see the on line help for more information.


DEBUG

Log server traces are by default disabled. To enable/disable log server traces 
in a running system, send signal USR1 to the osaflogd process. Every time the 
trace state is toggled. Example:

	$ pkill -USR2 osaflogd

Traces are written to the file:

	$pkglogdir/osaflogd

To enable traces from the very start of the log server, uncomment the line:

        #args="--tracemask=0xffffffff"

in logd.conf (see CONFIGURATION above) and restart the cluster.

For fatal errors syslog is used.


TEST
====

Currently a simple unit test can be found in 'tests/logsv/src'. The test suite
is built by the main make system and is either install by 'make install' or by
installing the tools rpm.


TODO
====

- Implement missing API functions:
	- saLogStreamOpenAsync_2
	- saLogWriteLog
	- saLogLimitGet
	- saLogFilterSetCallback
	- saLogStreamOpenCallback
- NID start of the log server process.
- Implement CLM interaction as described in 3.2
- Implement Log filtering (IMM needed for configuration)
- Implement log file full actions other than rotate
- Write optimization, no sync for log write
- Cleanup/act on "FIX" and "TODO" comments
- Revisit trace statements, cleanup
- Cleanup remains of edsv (search for 'channel')
- Implement "6 Alarms and Notifications" (NTF needed)
- On standby, query local MDS-layer for status of an agent before updating data
  structures during sync.
- Distributed testing
- Document manual test cases


IMPORTANT INFORMATION FOR CONTRIBUTORS/MAINTAINERS
==================================================

File IO
-------

File operations are no longer allowed in the log-server main thread. This is in
order to prevent "hanging" of the log-server if a file operation does not return
e.g. when a NFS filesystem is not working correctly. It is therefore very
important that no future code do any file-system operations in the main thread.

All file system operations are handled in a separate thread.
Use this thread to handle complete functions or parts of functions that has any
type of interaction with the file system. Internally all or some of the code is
done in a "handler" that is running in the second thread.
See lgs_filehdl.c, lgs_stream.c and lgs_util.c for examples.
Functions that uses a "handler" has got extention _h in the function name
e.g. fileopen(..) -> fileopen_h(..). All handlers can be found in file
lgs_filehdl.c

Note on memory handling for writting log record:
------------------------------------------------
In most cases, the main thread is blocked until the log handler
thread finishes the request (e.g: writing log record to file). Therefore,
when the main thread is unblocked, it is safe to free the log record
memory by the main thread as the log handler thread no longer uses it.

But in time-out case, it is unsure when the log handler thread no longer uses
the log record memory. So, in worse case, if the log record memory is freed
by the main thread while the log handler is still using it, could cause the
problem.

To make sure there is no corruption of memory usage in case of time-out,
leave the log record memory free to log handler thread.

Refer to ticket #1376 for more info on this.

File system configuration:
When using UML (tools/cluster_sim_uml) the file system can be configured for
both shared and split file system. This is done by setting the value of
logFileSysConfig in logsv_objects.xml before running the ./build_uml script.


Log service configuration
-------------------------

An IMM object is used to set and store the configuration of the log service.
It is not practical to read configuration data from the IMM object every time
configuration data is needed; instead an internal store in the server is used.
When a log server is started the configuration store is updated with
configuration data read from the IMM object or environment variables. If no
external configuration data exist hard coded default values are used.

All handling of configuration data can be found in the file lgs_config.c (h).
The structure used for storing the configuration is local to this file and shall
never be used directly in other files. To read configuration data the
lgs_cfg_get(...) function shall be used. Also never store any configuration data
elsewhere e.g. in the lgs_cb structure.


Summary of important functions. For more detailed info see lgs_config.c:

lgs_cfg_init()
Initiate configuration structure. Used once when a log server is started.

lgs_cfg_get()
Used to get/read configuration data. Used together with lgs_logconfGet_t;
see lgs_config.h. Configuration data should not be read in any other way.
The function is tread safe (see also lgs_cfg_update()).

lgs_cfgupd_list_create()
Used to create a list for configuration information. Contains attribute names
and their values. The list may contain one or more attributes. The list is used
for updating configuration data checkpointing etc. Typically a list is created
when OI is reading a ccb in the apply callback.

lgs_cfgupd_list_read()
Read data from a cfgupd list.

lgs_cfg_update()
Updates the configuration store using a cfgupd list as input.
The function is tread safe (see also lgs_cfg_get()).

lgs_rootpathconf_set()
lgs_groupnameconf_set()
These functions exist in order to support older versions of checkpointing.
Shall never be used in new code! Instead lgs_cfgupd_list_create() and
lgs_cfg_update() shall be used.


Checkpointing:
Previously configuration data was checkpointed using a checkpoint structure
in the same way as checkpointing is done for other changes. This is changed.
Configuration changes are now checkpointed using a variable length buffer
containing a cfgupd list.

With this change, when attributes are check pointed,
the list is always updated with all check pointed values.

CONTRIBUTORS/MAINTAINERS
========================

Arne Eriksson <Arne.R.Eriksson@ericsson.com>
Hans Feldt <Hans.Feldt@ericsson.com>
Niklas Nilsson
Lennart Lund <lennart.lund@ericsson.com>

The LOG service was originally cloned from the edsv service.


=================
Split file system
=================


GENERAL

The log service can be configured to be used without a shared file system.
In this configuration all handling of log files is done on both nodes local file
system.


CONFIGURATION

The log service must be able to handle files in two ways.

1. Using a shared file system the same way as today.

2. Using the local file system on both nodes. The same log records will be
   written on both file systems. The directory structure and file names are
   also the same.

An attribute in the log service configuration object is used to select
configuration. Default configuration is shared file system (configuration 1).


CHECKPOINTING

Only the active node will receive requests from the agent. The request are
handled in the event handler (lgs_evt). The standby node will get information
about the requests from the active node via check pointing.

In configuration 1; standby will use this information to update the internal
information structure e.g. information about connected clients, used file names
etc. but no files will be created or written.

In configuration 2; standby will also create and open files and write log
records. This is done in the check point handlers (lgs_mbcsv) that corresponds
to the event handlers on the active node.

As is changes of the log service configuration object is handled on standby
using IMM applier. This is changed so that mbcsv is used for all
synchronization.


The following is checkpointed and done on standby:
===================================================

If something goes wrong the general behavior is to restart the component using
saAmfComponentErrorReport(...,SA_AMF_COMPONENT_RESTART,...) in order to avoid
being out of sync (will trig a mbcs cold sync).

Checkpointed
-------------

initialize client:
    Adds a new client.

finalize client:
	Removes a client. Also removes streams that has no more clients.

    If config 2:

    closing and renaming the corresponding files.

agent down:
    Client corresponding to MDS destination is removed. See also finalize.

log write:
    The following is checkpointed and internal data is updated:
    logRecordId
    curFileSize
    logFileCurrent

    If config 2:

    logRecordString
    logRecordSize

    Create files if new stream.
    Write record to log file.
    Rotate if logFileCurrent changes.
    
open stream:
    Log files are created when a stream is opened for the first time. This means
    creating the file names, creating a config file and creating and opening the
    log file. If this fails the files are created and opened when trying to
    write a log record to the stream. This is done in the event handler when
    receiving an "stream open" event from the agent.
    After created, all these files will be owned by LOGSV_DATA_GROUPNAME if set (in
    either config 1 or 2).

    If config 2:

    As above but is done in the check point handler when receiving an "open
    stream" check point.


close stream:
    A log stream is closed for a client.
    
    If config 2:

	If last client files are closed and renamed same as on active node.

cfg stream:
    Attributes for a log stream are changed. Internal data is updated. This is
    done for both streams with runtime objects and configuration objects. On
    active node this is handled with an object implementer (lgs_imm) and changes
    are check pointed to standby.

    If config 2:

    In some cases the configuration file and log file has to be handled. Must
    be done also on standby. This is done in the check point handler.

cfg config:
    Attributes in the log service configuration object are changed. Internal
    data is updated. On active node this is handled with an object implementer
    (lgs_imm) and changes are check pointed to standby.

If config 2 log records:
    Log records are checkpointed and written to file on standby
    Files has to be handled as on active. This is done in the check point
    handler.


SYNCHRONIZATION

Synchronization of internal data
--------------------------------

The only synchronization that is used in the log service is mbcs cold sync. This
synchronization is trigged when standby detects a new active.
Cold sync:
 - At start up / restart
 - When changing role
 - When standby detects out of sync.
   AMF is requested to perform a component restart (of standby)
   "saAmfComponentErrorReport(...,SA_AMF_COMPONENT_RESTART,...)"


Synchronization of files and handling of log records
----------------------------------------------------

Active node check point parameter used for file handling changes to standby.

On standby if configuration 2:
 - Log files are created when a stream is opened for the first time. This means
   creating the file names, creating a config file and creating and opening the
   log file. If this fails the files are created and opened when trying to write
   a log record to the stream.
 - Rotate log files when "logFileCurrent" change (means that file rotation has
   been done on active). Also rotate if the log files reaches it's size limit.
   In this case the new file name is based on time read from own node.
   If active check point a new "logFileCurrent" after a local file has been
   created a file rotation is done and "logFileCurrent" is used as new file
   name.

 - For log records, time stamp and log-record-id checkpointed from active is
   always used on standby.
 - In some situations log records can be out of sync e.g. if standby is
   restarted when active is writing log records. The log server detects this by
   comparing last written log record id with the id of a log record to be
   written. The id to write shall be last + 1 if we are in sync.
   If out of sync the following is done:
   - The log service creates a log record with id 0 (id 0 is not used for "real"
     log records) and writes it to the stream log file. This log record has the
     same format as the other log records. It contains a message with
     information about the problem. The message also contains the Id of the
     previous record and the Id of the record to be written.
   - Write the check pointed log record.

LOG SERVICE ENHANCEMENTS
========================

1. New tokens are added (#593)
------------------------------
Currently, the log service presents the time in the local time settings.
For example, if the log service is initiated in Stockholm, the log service
shows the local Stockholm time.

According to AIS standard, this time should be represented in UTC/GMT format.

To cover this, new optional tokens are added to show "time zone" (@Cz, @Nz).
- @Cz: for system and application log stream.
- @Nz: for alarm and notification log stream.

It should represent 04 numbers and an additional `+` or `-` sign in the beginning.
Preceding and trailing zeros (0) if needed should exist.

Format: [+,-]hhmm

In addition, two more tokens are added to show three digits millisecond
of second from log timestamp (@Ck, @Nk).
- @Ck: for system and application log stream.
- @Nk: for alarm and notification log stream.

Preceding and trailing zeros (0) if needed should exist.


2. Log record size could be up to 65535 bytes (#1288)
----------------------------------------------
With this ticket, logMaxLogrecsize and logFileIoTimeout attributes
could be possible to change in runtime.

logMaxLogrecsize attribute value could be up to 65535 bytes.

logFileIoTimeout, this attribute defines the time period for
which the main thread has to wait for the file IO operation to complete.
The value is in milliseconds. In default, the main thread waits up to 500ms
for file handling thread complete file IO operation.

If user suffers the timeout when sending a big record size (e.g: 65535 bytes),
the user can adjust the waiting time by updating logFileIoTimeout attribute value up to 5000ms.

3. New tokens are added (#1480)
-------------------------------
- @Cp: for showing the network name
- @Cq: for showing node name where the log record comes from.

a) The network name comes from an attribute, `opensafNetworkName`
   which belongs to the `OpensafConfig` class.
   The `opensafConfigId=opensafGlobalConfig,safApp=OpenSAF` object of this class is an
   OpenSAF global configuration object.

   LOG service is an applier for this object, so that whenever there is change of
   network name attribute `opensafNetworkName`, LOG service will be notified.

b) Regarding node name, LOG service gets this information when decoding messages at MDS layer.

4. Cluster Membership (CLM) integration (#1638)
-----------------------------------------------
With this ticket, CLM integration is supported from Log Service A.02.02
 
At-least a A.02.02 LGA client will check CLM membership status of client's
node. old LGA clients A.02.01 are always clm member.
 
With these changes Log Service API on a Non-Member Node will fail with
SA_AIS_ERR_UNAVAILABLE on cluster nodes that are not in the cluster membership.
 
Implementation note :
LGS is a Pre CLM & AMF service and it can have Agents (LGA`s )
before CLM & AMF service available,so doing CLM initialize based
on AMF role is unnecessary delay the CLM state of a Node
(CLM state will available as soon as CLM started), so LGS is a taking
AVD Up event as trigger to do CLM initialize.
 
